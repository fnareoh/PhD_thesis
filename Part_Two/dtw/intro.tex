Introduced more than forty years ago~\cite{sakoe1978dynamic}, the dynamic time warping ($\dtw$) distance has become an essential tool in the time series analysis and its applications due to its ability to preserve the signal despite speed variation in compared sequences. To measure the $\dtw$ distance between two discrete temporal sequences, one must ``warp'' them, that is, replace some data items in the sequences with multiple copies of themselves to obtain two equal-lengths sequences, and then sum the distances between the data items in the corresponding positions. 

The $\dtw$ distance has been extensively studied for parameterized curves~--- sequences where the data items are points in a multidimensional space~---  specifically, in the context of locality sensitive hashing and nearest neighbor search~\cite{LSH,ANN}. In this work, we focus on a somewhat simpler, but surprisingly much less studied setting when the data items are elements of a finite set, the alphabet. Following traditions, we call such sequences \emph{strings}. 

The classical textbook dynamic programming algorithm computes the $\dtw$ distance between two $N$-length strings in $\Oh(N^2)$ time and space. Unfortunately, unless the Strong Exponential Time Hypothesis is false, there is no algorithm with strongly subquadratical time even for ternary alphabets~\cite{DBLP:conf/focs/AbboudBW15,DBLP:conf/focs/BringmannK15,DBLP:conf/icalp/Kuszmaul19}. On the other hand, very recently Gold and Sharir~\cite{DBLP:journals/talg/GoldS18} showed the first weakly subquadratic time algorithm (to be more precise, the time complexity of the algorithm is~$\Oh(N^2 \log \log  \log N / \log \log N)$). Kuszmaul~\cite{DBLP:conf/icalp/Kuszmaul19} gave a $\Oh(kN)$-time algorithm that computes the value of the distance between the strings if it is bounded by $k$, assuming that the distance between any two distinct letters of the alphabet is at least one, and used it to derive a subquadratic-time approximation algorithm for the general case. Finally, it is known that binary strings admit much faster algorithms: Abboud, Backurs, and Vassilevska Williams~\cite{DBLP:conf/focs/AbboudBW15} showed an $O(N^{1.87})$-time algorithm followed by a linear-time algorithm by Kuszmaul~\cite{DBLP:journals/corr/abs-2101-01108}. 

The problem of computing the $\dtw$ distance has also been studied in the sparse and run-length compressed settings, as well as in the low distance regime.  
In the sparse setting, we assume that most letters of the string are zeros. Hwang and Gelfand~\cite{hwang2017sparse} gave an $\Oh((s+t) N)$-time algorithm, where $s$ and $t$ denote the number of non-zero letters in each of the two strings. On sparse binary strings, the distance can be computed in $\Oh(s+t)$ time~\cite{DBLP:conf/mldm/HwangG19,mueen2016awarp}. Froese et al.~\cite{DBLP:journals/corr/abs-1903-03003} suggested an algorithm with running time $\Oh(mN+nM)$, where $M,N$ are the length of the strings, and $m, n$ are the sizes of their run length encodings. If $n \in \Oh(\sqrt{N})$ and $m \in \Oh(\sqrt{M})$, their algorithm runs in time $\Oh(nm \cdot (n+m))$. For binary strings, the $\dtw$ distance can be computed in $\Oh(nm)$ time~\cite{DBLP:conf/pkdd/DupontM15a}. 

Nishi et al.~\cite{DBLP:conf/spire/NishiNIBT20} considered the question of computing the $\dtw$ distance in the dynamic setting when the stings can be edited, and Sakai and Inenaga~\cite{DBLP:conf/isaac/SakaiI20} showed a reduction from the problem of computing the $\dtw$ distance to the problem of computing the longest increasing subsequence, which allowed them to give polynomial-time algorithms for a series of $\dtw$-related problems. 

In this work, we focus on the pattern matching variant of the problem: Given a pattern $P$ and a text $T$, one must output the smallest $\dtw$ distance between~$P$ and a suffix of $T[1 \dd r]$ for every position $r$ of the text. 

Our interest to this problem sparks from its potential applications in Third Generation Sequencing (TGS) data comparisons. TGS has changed the genomic landscape as it allows to sequence reads of few dozens of thousand of letters where previous sequencing techniques were limited to few hundred letters~\cite{amarasinghe2020opportunities}. However, TGS suffers from a high error rate (from $\approx$ 1 to 10\% depending on the used techniques) mainly due to the fact that the DNA sequences are read and thus sequenced at an uneven speed. The uneven sequencing speed has a major impact in the sequencing quality of DNA regions composed of two or more equal consecutive letters. Those regions, called \emph{homopolymers}, are hardly correctly sequenced as, due to the uneven sequencing speed, their size cannot be precisely determined~\cite{huang_homopolish_2021}. In particular, a common post-sequencing task  consists in aligning the obtained reads to a reference genome. This enables for instance to predict alternative splicing and gene expression~\cite{gonzalez2016introduction} or to detect structural variations~\cite{mahmoud2019structural}. All known aligners use the edit distance, most likely, due to the availability of software tools for the latter (see~\cite{10.1093/bioinformatics/bty191} and references therein). However, we find that the nature of TGS errors is much better described by the $\dtw$ distance, which we confirm experimentally in Section~\ref{sec:experiments}.

\paragraph{Our contribution.}  As a baseline, the problem of pattern matching under the $\dtw$ distance can be solved using dynamic programming in time $\Oh(MN)$, where $M$ is the length of the pattern and $N$ of the text (Equation~\ref{eq:recursion}). 

In this work, we aim to show more efficient algorithms for the low-distance regime on run-length compressible data, which is arguably the most interesting setting for the TGS data processing. Formally, in the \emph{$k$-$\dtw$ problem} we are given an integer $k > 0$, a pattern $P$ and a text $T$, and must find all positions $r$ of the text such that the smallest $\dtw$ distance between the pattern $P$ and a suffix of $T[1 \dd r]$ does not exceed~$k$. One might hope that the $\dtw$ distance is close enough to the edit distance and thus is amenable to the techniques developed for the latter, such as~\cite{LMS98,LV97}. In the full version, we show that this is indeed the case for $k = 1$:

\begin{restatable}{lemma}{DTWone}
\label{lm:1-DTW}
Given run-length encodings of a pattern $P$ and of a text $T$ over an alphabet $\Sigma$ and a distance $d: \Sigma \times \Sigma \rightarrow \mathbb{Z}^+$, the $1$-$\dtw$ problem can be solved in $\Oh(m+n)$ time, where $m$ is the number of runs in $P$ and $n$ is the number of runs in $T$. The output is given in a compressed form, with a possibility to retrieve each position in constant time.
\end{restatable}

Unfortunately, extending the approach of~\cite{LMS98,LV97} to higher values of $k$ seems to be impossible as it is heavily based on the fact that in the edit distance dynamic programming matrix the distances are non-decreasing on every diagonal, which is not the case for the $\dtw$ distance (see Fig.~\ref{fig:decreasing}). 

In Section~\ref{sec:block} we develop a different approach. Interestingly, we show that the value of any cell of the bottom row and the right column of a block of the dynamic programming table (i.e. a subtable formed by a run in the pattern and a run in the text) can be computed in constant time given a constant-time oracle access to the left column and the top row. Combining this with a compact representation of the $k$-bounded values, we obtain the following result:

\begin{theorem}\label{th:block}
Given run-length encodings of a pattern $P$ and of a text $T$ over an alphabet $\Sigma$ and a distance $d: \Sigma \times \Sigma \rightarrow \mathbb{Z}^+$, the $k$-$\dtw$ problem can be solved in $\Oh(k mn)$ time, where $m$ is the number of runs in $P$ and $n$ is the number of runs in $T$. The output is given in a compressed form, with a possibility to retrieve each position in constant time.
\end{theorem}

We note that while our algorithm can be significantly faster than the baseline, its worst-case time complexity is cubic. We leave it as an open question whether there exists an $\Oh(k \cdot (m+n))$-time algorithm.  Finally, in Section~\ref{sec:approx} we use Theorem~\ref{th:block} to derive an approximation algorithm for the general variant of pattern matching under the $\dtw$ distance. 

\begin{figure}[H]
\inputDTW{figures/example_block}
\caption{Consider $P = AATTAT$ and $T=GGTTTTCTTATTTTGGTGATA$. A cell $(i,j)$ contains the smallest $\dtw$ distance between $P[1\dd i]$ and $T[1\dd j]$, where the distance between two letters equals one if they are distinct and zero otherwise. A non-monotone diagonal of the table is shown in red.}  
\label{fig:decreasing}
\end{figure}

\section{Proofs omitted from Section~\ref{indexgapped:sec:prelim}}\label{app:proofs}

\tries*
\begin{proof}
Let us first recall the definition of the Karp--Rabin fingerprint.

\begin{definition}[Karp--Rabin fingerprint]
For a prime~$p$ and an~$r \in \mathbb{F}_p^\ast$, the \emph{Karp--Rabin fingerprint}~\cite{karp1987efficient} of a string~$X$ is defined as a tuple $(r^{|X|-1} \mod p, r^{-|X|+1} \mod p, \varphi_{p,r}(X))$, where $\varphi_{p,r}(X)=\sum_{k=0}^{|X|-1} S[k]r^k\mod p$.
\end{definition}

We use the following result of Christiansen et al.~\cite{talg/ChristiansenEKN21}, which builds on Belazzougui~et~al.~\cite{esa/BelazzouguiBPV10} and Gagie~et~al.~\cite{latin/GagieGKNP14,soda/GagieNP18}.
 
\begin{fact}[{\cite[Lemma 6.5]{talg/ChristiansenEKN21}}]\label{fact:compact_trie}
Let $\mathcal{S}$ be a set of strings and assume we have a data structure supporting extraction of any length-$l$ prefix of strings in $\mathcal{S}$ in
time $f_e(l)$ and computing the Karp--Rabin fingerprint $\varphi$ of any length-$l$ prefix of a string in $\mathcal{S}$
in time $f_h(l)$. We can then build a data structure that uses $O(|\mathcal{S}|)$ space and supports the following queries in $O(m + f_e (m) + \tau ( f_h (m) + \log m))$ time: Given a pattern $P$ of length $m$ and $\tau > 0$
suffixes $Q_1,\dots,Q_{\tau}$ of $P$, find the intervals of strings in (the lexicographically-sorted) $\mathcal{S}$ prefixed by
$Q_1,\dots,Q_{\tau}$.
\end{fact}

It should be noted that despite using a hash function, the query algorithm is deterministic: the proof shows that $p$ and $r$ can be chosen during the construction time to ensure that there are no collisions on the substrings of the strings in $\mathcal{S}$.  

To bound $f_e$, we use~\cite[Lemma 6.6]{talg/ChristiansenEKN21} which builds on G\k{a}sieniec et al.~\cite{dcc/GasieniecKPS05} and Claude and Navarro~\cite{spire/ClaudeN12a}.

\begin{fact}[{\cite[Lemma 6.6]{talg/ChristiansenEKN21}}]\label{fact:prefsuf_extraction} Given an RLSLP
of size $O(g)$, there exists a data structure of size $O(g)$ such that any length-$l$ prefix or suffix of $\str{A}$ can be
obtained from any non-terminal $A$ in time $f_e(l) = O(l)$.
\end{fact}

To bound $f_h(l)$, we introduce a simple construction based on the following well-known fact:

\begin{fact}\label{fact:fingerprints}
Consider strings $X,Y,Z$ where $XY = Z$. Given the Karp--Rabin fingerprints of two of the three strings, one can compute the fingerprint of the third string in constant time.
\end{fact}

\begin{claim}\label{claim:fingerprint_extraction}
Given a RLSLP $G$ of size $g$ and height $h$, there exists a data structure of size $O(g)$ that given a non-terminal $A$ and an integer $l$ allows to retrieve the Karp-Rabin fingerprints of the length-$l$ prefix and suffix of $\str{A^r}$ and $\rev{\str{A^r}}$ in time $f_h(l) = O(h + \log l)$.
\end{claim}
\begin{proof}
The claim for $\rev{\str{A^r}}$ follows for the claim for $\str{A^r}$ by considering the grammar $G_{rev}$, where the order of the non-terminals in each production is reversed. Below we focus on extracting the fingerprints for $\str{A^r}$, and we further restrict our attention to prefixes of $\str{A^r}$, the algorithm for suffixes being analogous. 

The data structure consists of two sets. The first set contains the lengths of the expansions of all non-terminals in the grammar, and the second one their fingerprints. 
 
By Fact~\ref{fact:fingerprints} and doubling, it suffices to show an algorithm for computing the fingerprint of the length-$l$ prefix of $\str{A}$. Assume that $A$ associated with a rule $A\rightarrow BC$. If the length of $\str{A}$ is smaller than $l$, we return error. Otherwise, to compute the fingerprint of the length-$l$ prefix of $\str{A}$, we consider two cases. If $l\leq |\str{B}|$, we recurse on $B$ to retrieve the fingerprint of the $l$-length prefix of $\str{B}$. Otherwise, we recurse on $C$ to retrieve the fingerprint of $\str{C}[\dots l-|\str{B}|)$ and then compute the fingerprint of the $l$-length prefix of $\str{A}$ from the fingerprints of $\str{B}$ and $\str{C}[\dots l-|\str{B}|)$ in constant time by Fact~\ref{fact:fingerprints}. 

For a non-terminal $A$ associated with a rule $A\rightarrow B^{r}$, we compute the fingerprint analogously. If the length of $\str{A}$ is smaller than $l$, we return error. Otherwise, let $q$ be such that $q \cdot |\str{B}| \leq l < (q+1) \cdot |\str{B}|$. We compute the fingerprint of $\str{B}^q$ from the fingerprint of $\str{B}$ by applying Fact~\ref{fact:fingerprints} $O(1+\log q)$ times, and the fingerprint of $\str{B}[\dots l-q \cdot |\str{B}|)$ recursively. We can then apply Fact~\ref{fact:fingerprints} to compute the fingerprint of the length-$l$ prefix of $\str{A}$ in constant time. Note that in this case, the length of the prefix decreases by a factor at least $q$. 

If we are in a terminal $A$, the calculation takes $O(1)$ time (the prefix must be equal to $A$ itself). 
 
In total, we spend $O(h+\log l)$ time as we recurse $O(h)$ times, and whenever we spend more than constant time in a symbol, we charge it on the decrease in the length. The fingerprints of length-$l$ suffixes are computed analogously.
\end{proof}


By substituting the bounds for $f_e(l)$ (Fact~\ref{fact:fingerprints}) and $f_h(l)$ (Claim~\ref{fact:prefsuf_extraction}) into Fact~\ref{fact:compact_trie}, we obtain the claim of the lemma.
\end{proof}

\section{Proofs omitted from Section~\ref{indexgapped:sec:occurrences}}
\label{app:occurrences}
\begin{claim}\label{claim:leftmost_rightmost}
Given a non-terminal $A$ of $G'$, we can find the leftmost and the rightmost occurrences of $P$ in $\str{A}$ and as a corollary in $\str{\head(A)}$ and $\str{\tail(A)}$ in $O(\log^{2} N\log\log N)$ time.  % h splits \log^{\eps} N
\end{claim}
\begin{proof}
We explain how to find the leftmost occurrence of $P$ in $\str{A}$, the rightmost one can be found analogously. We first check whether $\str{A}$ contains an occurrence of $P$ via Claim~\ref{claim:emptiness} in $O(\log N\log \log N)$ time. If it does not, we can stop immediately. Below we assume that there is an occurrence of $P$ in  $\str{A}$. Next, we check whether $\str{\head(A)}$ contains an occurrence of $P$ via Claim~\ref{claim:emptiness} in $O(\log N\log \log N)$ time. If it does, the leftmost occurrence of $P$ in $\str{A}$ is the leftmost occurrence of $P$ in $\str{\head(A)}$ and we can find it by recursing on $\head(A)$. If $\str{\head(A)}$ does not contain an occurrence of $P$, but $\str{A}$ contains relevant occurrences of $P$, then the leftmost occurrence of $P$ in $\str{A}$ is the leftmost relevant occurrence of $P$ in $\str{A}$ and we can find it in $O(|\splits(G',P)|) = O(\log N)$ time. Finally, if $P$ neither occurs in $\str{\head(A)}$ nor has relevant occurrences in $\str{A}$, then the leftmost occurrence of $P$ in $\str{A}$ is the leftmost occurrence of $P$ in $\str{\tail(A)}$. If $\tail(A)$ is a non-terminal $C$, we recurse on $C$ to find it. If $\tail(A)=B^{r-1}$ for a non-terminal $B$, $\str{\tail(A)}$ cannot contain an occurrence of $P$ because $\str{B}$ does not contain $P$ and there are no relevant occurrences in $A$. We recurse down at most $h = O(\log N)$ levels, and spend $O(\log N\log \log N)$ time per level. The claim follows.
\end{proof}

\begin{lemma}\label{lm:predecessor}
Let $A$ be a non-terminal of $G'$. For any position $p$, we can find the rightmost occurrence $q \le p$ of $P$ in $\str{A}$ and the leftmost occurrence $q'\geq p$ of $P$ in $\str{A}$ in $O(\log^{3} N\log \log N)$ time.  
\end{lemma}
\begin{proof}
First we describe how to locate $q$. Consider a node $u$ of the parse tree of $G'$ labeled by $A$. The algorithm starts at $u$ and recurses down. Let $A'$ be the label of the current node. It computes the leftmost and rightmost occurrences in $\str{A'}$, $\str{\head(A')}$ and $\str{\tail(A')}$ as well as all relevant occurrences via Claim \ref{claim:leftmost_rightmost}. If the leftmost occurrence of $P$ in $\str{A'}$ is larger than $p$, the search result is empty. Otherwise, consider two cases. 

\begin{enumerate}
\item $A'$ is associated with a rule $A' \rightarrow B'C'$, i.e. $\head(A') = B'$, $\tail(A') = C'$. 
\begin{enumerate}
\item If $p \le |\str{B'}|$, recurse on $B'$. 
\item Assume now that $p > |\str{B'}|$. If the leftmost  occurrence of $P$ in $\str{C'}$ is smaller than $p$, recurse on $C'$. Otherwise, return the rightmost relevant occurrence of $P$ in $\str{A'}$ if it exists else the rightmost occurrence of $P$ in $\str{B'}$. 
\end{enumerate}
\item $A'$ is associated with a rule $A \rightarrow (B')^r$, i.e. $\head(A') = B'$, $\tail(A') = (B')^{r-1}$.  Let an integer $k$ be such that $(k-1) \cdot |\str{B'}|+1 \le p \le k \cdot |\str{B'}|$. The desired occurrence of $P$ is the rightmost one of the following ones:
\begin{enumerate}
	\item The rightmost occurrence $q \le p$ of $P$ which crosses the border between two copies of $\str{B'}$. To compute $q$, we compute all relevant occurrences of $P$ in $\str{A'}$ and then shift each of them by the maximal possible shift $r' \cdot |\str{B'}|$, where $r'$ is an integer, which guarantees that it starts before $p$ and ends before $|\str{A'}|$ and take the rightmost of the computed occurrences to obtain $q$.
	\item The rightmost occurrence $q$ of $P$ such that for some integer $k'$, we have $(k'-1) \cdot |\str{B'}| \le q \le q+|P|-1 \le k' \cdot |\str{B'}|$ (i.e. the occurrence fully belongs to some copy of $\str{B'}$). In this case, $q$ is either the rightmost occurrence of $P$ in the $(k-1)$-th copy of $\str{B'}$, or the rightmost occurrence of $P$ in the $k$-th copy of $\str{B'}$ that is smaller than $p$. In the second case, we compute $q$ by recursing on $B'$.
	\end{enumerate}
\end{enumerate}
 We recurse down at most $h$ levels. On each level we spend $O(\log^{2} N\log\log N)$ time to compute the leftmost, the rightmost, and relevant occurrences and respective shifts for a constant number of non-terminals via Claim~\ref{claim:leftmost_rightmost}. Therefore, in total we spend $O(h \cdot \log^{2} N\log\log N) = O(\log^{3} N\log\log N)$ time. 
 
 
Locating $q'$ is very similar and differs only in small technicalities. The algorithm starts at the node $u$ and recurses down. Let $A'$ be the label of the current node. We compute the leftmost and rightmost occurrences in $\str{A'}$, $\str{\head(A')}$ and $\str{\tail(A')}$ as well as all relevant occurrences via Claim \ref{claim:leftmost_rightmost}. If the rightmost occurrence of $P$ in $\str{A'}$ is smaller than $p$, the search result is empty. Otherwise, consider two cases. 

\begin{enumerate}
\item $A'$ is associated with a rule $A' \rightarrow B'C'$, i.e. $\head(A') = B'$, $\tail(A') = C'$. 
\begin{enumerate}
\item If $p > |\str{B'}|$, recurse on $C'$. 
\item Assume now that $p \leq |\str{B'}|$. If the rightmost  occurrence of $P$ in $\str{B'}$ is larger than $p$, recurse on $B'$. Otherwise, return the leftmost relevant occurrence $q$ satisfying $q\geq p$, if it exists, and otherwise the leftmost occurrence of $P$ in $\str{C'}$. %Otherwise, return the rightmost relevant occurrence of $P$ in $\str{A'}$ if it exists else the rightmost occurrence of $P$ in $\str{B'}$. 
\end{enumerate}
\item $A'$ is associated with a rule $A \rightarrow (B')^r$, i.e. $\head(A') = B'$, $\tail(A') = (B')^{r-1}$.  Let an integer $k$ be such that $(k-1) \cdot |\str{B'}|+1 \le p \le k \cdot |\str{B'}|$. The desired occurrence of $P$ is the leftmost one of the following ones:
\begin{enumerate}
	\item The leftmost occurrence $q' \geq p$ of $P$ which crosses the border between two copies of $\str{B'}$. To compute $q'$, we compute all relevant occurrences of $P$ in $\str{A'}$ and then shift each of them by the minimal possible shift $r' \cdot |\str{B'}|$, where $r'$ is an integer, which guarantees that it starts after $p$ and ends before $|\str{A'}|$ (if it exists) and take the leftmost of the computed occurrences to obtain $q$.
	\item The leftmost occurrence $q'$ of $P$ such that for some integer $k'$, we have $(k'-1) \cdot |\str{B'}| \le q' \le q'+|P|-1 \le k' \cdot |\str{B'}|$ (i.e. the occurrence fully belongs to some copy of $\str{B'}$). In this case, $q'$ is either the leftmost occurrence of $P$ in the $(k+1)$-st copy of $\str{B'}$, or the leftmost occurrence of $P$ in the $k$-th copy of $\str{B'}$ that is larger than $p$. In the second case, we compute $q'$ by recursing on $B'$.
	\end{enumerate}
\end{enumerate}
The time complexities are the same as for computing $q$.
\end{proof}

\section{Proofs omitted from Section~\ref{indexgapped:sec:close}}
\label{app:close}

\computingrelevant*
\begin{proof}
We preprocess $P_1, P_2$ in $O(m \log N + \log^2 N)$ time as explained in Theorem~\ref{th:occurrences}. Upon receiving a non-terminal $A$, we compute the leftmost and the rightmost occurrences of $P_1, P_2$ in $\str{\head(A)}$ and $\str{\tail(A)}$, as well as a set $\Pi_1$ of all relevant occurrences of $P_1$ in $\str{A}$ and a set $\Pi_2$ of all relevant occurrences of $P_2$ in $\str{A}$ via Claim~\ref{claim:leftmost_rightmost}.
We will compute all relevant co-occurrences in $\str{A}$, selecting those of them that are $b$-close is then trivial. 
As $q_1 \le q_2$ by definition, each relevant co-occurrence $(q_1,q_2)$ of $P_1,P_2$ in $\str{A}$ falls under one of the following categories:

\begin{enumerate}
\item $q_1$ is a relevant occurrence of $P_1$ in $\str{A}$ and $q_2$ is a relevant occurrence of $P_2$ in $\str{A}$ (i.e. $q_1 \in \Pi_1, q_2 \in \Pi_2$). To check whether a pair $q_1 \in \Pi_1, q_2 \in \Pi_2$ forms a co-occurrence of $P_1, P_2$ in $\str{A}$, we must check whether there is an occurrence $q$ of either $P_1$ or $P_2$ between $q_1$ and $q_2$. The occurrence $q$ can only be the rightmost occurrence $r_q$ of $P_2$ in $\str{\head(A)}$, the leftmost occurrence $l_q$ of $P_1$ in $\str{\tail(A)}$, or an occurrence in $\Pi_1 \cup \Pi_2$. Consequently, we can find all co-occurrences in this category by merging two (sorted) sets: $\Pi_1 \cup \{l_q\}$ and $\{r_q\} \cup \Pi_2$, which can be done in $O(2 + |\Pi_1 \cup \Pi_2|)$ time.

\item $1 \le q_1  \le q_1+|P_1|-1 \le |\str{\head(A)}|$ and  $|\str{\head(A)}| < q_2 \le q_2+|P_2|-1$. In this case, $q_1$ must be the rightmost occurrence of $P_1$ in $\str{\head(A)}$ and $q_2$ the leftmost occurrence in $\str{\tail(A)}$, $q_1 \le q_2$, and there must be no occurrence $q \in \Pi_1 \cup \Pi_2$  such that $q_1 \le q \le q_2$. Therefore, if there is a co-occurrence in this category, we can retrieve it in $O(|\Pi_1 \cup \Pi_2|)$ time.

\item $q_1$ is a relevant occurrence of $P_1$ in $\str{A}$ (i.e. $q_1 \in \Pi_1$) and $|\str{\head(A)}| < q_2 \le q_2+|P_2|-1$. In this case, $q_1$ must be the rightmost occurrence in $\Pi_1$ and $q_2$ the leftmost occurrence of $P_2$ in $\str{\tail(A)}$, and there should be no occurrence from $\Pi_2$ between $q_1$ and $q_2$. Therefore, if there is a co-occurrence in this category, we can find it in $O(|\Pi_1 \cup \Pi_2|)$ time.

\item $q_1 \le q_1+|P_1|-1 \le |\str{\head(A)}|$ and $q_2$ is a relevant occurrence of $P_2$ in $\str{A}$ (i.e. $q_2 \in \Pi_2$). First, consider the leftmost occurrence in $q_2 \in \Pi_2$. We find the rightmost occurrence $q_1 \le q_2$  of $P_1$ in $\str{A}$ via a predecessor query. The pair $(q_1,q_2)$  is a co-occurrence iff the rightmost occurrence of $P_2$ in $\str{\head(A)}$ is smaller than $q_1$, which can be checked in constant time. Second, we consider the remaining occurrences in $\Pi_2$. Let $q_2'$ be the leftmost one. We begin by computing the preceding occurrence $q_1'$ of $P_1$ via a predecessor query and if $q_2 \le q_1'$, output the resulting co-occurrence. If $\Pi_2 = \{q_2, q_2'\}$, we are done. Otherwise, by Corollary~\ref{cor:arithmetic_progression}, the occurrences in $\Pi_2 \setminus \{q_2\}$ form an arithmetic progression with difference equal to the period of $P_2$ (as all of them contain the position $|\str{\head(A)}|$). Furthermore, as $P_1$ does not contain $P_2$, the occurrence of $P_1$ preceding $q_2'$ belongs to the periodic region formed by the relevant occurrences of $P_2$. Therefore, all the remaining co-occurrences can be obtained from the co-occurrence for $q_2'$ by shifting them by the period. In total, this step takes $O(|\Pi_2| + \log^{3} N\log\log N)$ time.
\end{enumerate}
\end{proof}

\begin{lemma}
\label{lem:close_co_occurr}
Assume that $P_2$ is not a substring of $P_1$. One can compute all $b$-close co-occurrences of $P_1, P_2$  in $S$ in time $O(m + (1+\occ) \cdot \log^{4} N \log\log N)$. 
\end{lemma}
\begin{proof}
During the preprocessing, we prune the parse tree: First, for each non-terminal $B$, all but the first node labeled by $B$ in the preorder is converted into a leaf and its subtree is pruned. For each node $v$ labeled by a non-terminal $B$, we store $\anc(v)$, the nearest ancestor $u$ of $v$ labeled by $A$ such that $u$ is the root or $A$ labels more than one node in the pruned tree. Second, for every node labeled by a non-terminal $A$ associated with a rule $A \rightarrow B^k$, we replace its $k-1$ rightmost children with a leaf labeled by $B^{k-1}$. We call the resulting tree \emph{the pruned parse tree} and for each node $v$ labeled by a non-terminal $B$ store $\nextnode(v)$, the next node labeled by $B$ in preorder, if there is one. As every non-terminal labels at most one internal node of the pruned parse tree and every node has at most two children, it occupies $O(g')$ space.

When the algorithm of Lemma~\ref{lm:non-term_close_co_occ} outputs $A \in \mathcal{N}'$, we compute all relevant co-occurrences $(q_1,q_2)$ in $\str{A}$ in time $O(\log^{3} N\log \log N)$ using Lemma~\ref{lem:relevant_co_occurr_A} and select those which satisfy $q_2-q_1 \leq b$.

Fix a $b$-close relevant co-occurrence $(q_1,q_2)$ in $\str{A}$. If $A$ is associated with a rule $A \rightarrow BC$, construct a set $\occ(A) := \{(q_1,q_2)\}$, and otherwise if $A$ is associated with a rule $A \rightarrow B^k$,
$$\occ(A) := \{(q_1+i \cdot |\str{B}|, q_2+i \cdot |\str{B}|) : 0 \le i \le \lfloor (|\str{A}|-q_2-|P_2|+1)/|\str{B}| \rfloor\}$$
Suppose that $A$ labels nodes $v_1, v_2, \ldots, v_k$ of the unpruned parse tree of $G'$ (by construction $v_1$ is not pruned and we assimilate it to the corresponding node in the pruned parse tree). If $W$ is a set of co-occurrences, denote for brevity $W+\delta = \{(q_1+\delta,q_2+\delta) : (q_1,q_2) \in W\}$. Below we show an algorithm that generates a set $\mathcal{S} = \cup_i \occ(A) + \off(v_i)$ that contains all secondary $b$-close co-occurrences due to $(q_1,q_2)$.  

We traverse the pruned parse tree, while maintaining a priority queue. The queue is initialized to contain the first node in the preorder labeled by $A$ together with $\occ(A)$. Until the priority queue is empty, pop a node $v$ and a set $W$ of co-occurrences of $P_1,P_2$ in the expansion of its label, and perform the following steps:
\begin{itemize}
\item\label{step:reporting} \underline{Reporting step:}  If $v$ is the root, report $W$;
\item \label{step:next} \underline{Next node step:} If $\nextnode(v)$ is defined, push $(\nextnode(v),W+\off(\nextnode(v))-\off(v))$;
\item \label{step:siblings} \underline {Sibling step:}  If $v$ is labeled by a non-terminal $B$ and its sibling by $B^k$, for some integer $k$, then $W := \cup_{0 \le i \le k} W+i \cdot |\str{B}|$
\item \label{step:anc} \underline{Ancestor step:} Push to the queue $(\anc(v),W+\off(\anc(v))-\off(v))$. 
\end{itemize}

By construction and as every node is connected with the root by a path of $\anc$ links, the algorithm generates all co-occurrences in $\mathcal{S}$. 

Let us show that it reports every co-occurrence in $\mathcal{S}$ at most once. Assume that a co-occurrence was reported twice by two different sequences of nodes. 
Let $u,w$ be the first nodes in the sequences where the same co-occurrence $(q_1,q_2) \in \mathcal{S}$ was created. Note that ancestor steps do not create new occurrences, but only update already created ones. Therefore, we have only three possible cases for $u,w$: either we generated $(q_1,q_2)$ because the node equals to $v_1$, or we applied the next node step, or we applied the sibling step. We cannot have $u = w = v_1$, as $v_1$ is considered by the algorithm only once due to the fact that the preorder number of the current node increases both after the next node step and the ancestor step. Suppose now that $u = v_1$ and that we applied the next node or the sibling step to $w$. Neither $\nextnode(w)$ nor the siblings of $w$ can be in the subtree of $u$. On the other hand, $u$ cannot be neither in the subtree of $\nextnode(w)$ nor in the subtrees of the siblings of $w$ (they are pruned). Therefore, in this case we could not generate $(q_1,q_2)$ both for $u$ and $w$. If we generated $(q_1,q_2)$ by applying the next node step to $u$ and the next node step to $w$, then by the choice of $u,w$, we have $\nextnode(u)\neq \nextnode(w)$. Furthermore, neither $\nextnode(u)$ can be an ancestor of $\nextnode(w)$, nor vice versa, as the subtrees of $\nextnode(u)$ and $\nextnode(w)$ are pruned, and therefore we could not create $(q_1,q_2)$ both for $u$ and $w$. If $(q_1,q_2)$ was generated by applying the next node step to $u$ and the sibling step to $w$, then $u \neq w$ by definition and as the subtree of $\nextnode(u)$ is pruned, neither $w$ nor its siblings can be descendants of $u$. On the other hand, the subtrees and the siblings of $w$ are pruned, and cannot be ancestors of $\nextnode(w)$. A contradiction. Finally, consider the case when we apply the sibling step both to $u$ and $w$. In this case, the subtrees of the siblings of $u$ and $w$ are pruned by construction, and neither $u$ can belong to a subtree of a sibling of $w$, nor vice versa, and therefore we cannot generate $(q_1,q_2)$ both for $u$ and $w$. All remaining cases are symmetrical.  

The time complexity follows: The algorithm of Lemma~\ref{lm:non-term_close_co_occ} takes $O(m +(1+\occ) \cdot \log^3 N)$ time; applying Lemma~\ref{lem:relevant_co_occurr_A} to every non-terminal in $\mathcal{N}'$ takes $O(\occ \cdot \log^{4} N\log\log N)$ time; and maintaining the queue and reporting the co-occurrences takes $O(\occ)$ time as at every step we can charge the time needed to update the queue on newly created co-occurrences. 
\end{proof}


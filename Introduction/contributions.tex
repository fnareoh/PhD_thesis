 \section{Contributions}\label{intro:sec:contrib}

 \todo[inline]{Work In Progress, do not review}

So far, we presented the two core challenges at the heart of text processing: enabling relevant (and sometimes complex) queries suited to specific applications and while maintaining performances that can scale to the large volumes of input data.
%
This thesis makes theoretical and practical contributions to address both needs. 
Each contribution is presented as an independent chapter corresponding to a publication. This choice was motivated by the variety of subjects and techniques as well as how they were conceived as independent projects (with varying sets of co-authors) during the Ph.D. This section is meant to give an overview of the main contributions of the thesis and how they relate to the concept of sketches.



Part~ \ref{part:complex_queries} focuses on a theoretical study of complex queries. 
%
% Regular expressions
We start with regular expression search in the streaming setting.
%
As mentioned previously, the streaming model considers that the regular expression $R$ that we search for and the length of the stream $n$ are given in advance and can be preprocessed, then the text $T$ arrives one character at a time. For regular expression \emph{membership} we must answer after having seen $T$ entirely whether it is recognized by $R$, while for \emph{pattern matching}, at each position $r$ we must answer whether there exist a substring $T[l..r]$ recognized by $R$.
% Talk about the lowerbounds ?
% Main contribution
In Chapter~\ref{chap:regexp}, our main contribution is to identify $d$ the number of union symbol and Kleene star in $R$ as the key parameter that allows for a space efficient streaming algorithm. We design randomized Monte Carlo algorithms (meaning the execution time is deterministic, but the algorithms can err with small probability) that solve respectively regular expression membership and pattern matching in $\Oh(d^3\polylog n)$ space and $\Oh(nd^5\polylog n)$ time per character of $T$ (Theorem~\ref{th:memb}).
% Previous uses of the parameter
This parameter had already been used by Bille and Thorup~\cite{doi:10.1137/1.9781611973075.104}\footnote{They actually consider $k$ the number of strings appearing in $R$ but $k=\Theta(d)$.} who showed algorithms (not in streaming) for answering membership and pattern matching in $\Oh(m)$ space and $\Oh(n(\frac{d\log w}{w} + \log d))$ time with $w$ the size of the machine word.
% Links to previous results in streaming
In the streaming model, this parameter was already known for the two special cases of streaming dictionary matching and don't care matching. To match a dictionary of patterns $\{P_1, P_2, ... P_d \}$, which corresponds to pattern matching for the regular expression $(P_1| P_2| ... | P_d)$, a series of results~\cite{Porat:09,DBLP:journals/talg/BreslauerG14,DBLP:conf/esa/CliffordFPSS15,DBLP:conf/esa/GolanP17,DBLP:conf/icalp/GolanKP18} lead to a randomized Monte Carlo algorithm in $\Oh(d\log m)$ space and $\Oh(\log \log |\Sigma|)$ time per character.
While don't care matching for a pattern $P_1 ? P_2 ... ? P_d$ where $P_i$, $i \in [1,d]$, are strings (possibly empty) over $\Sigma$, can be written as matching $R = P_1 (1|2|\ldots|\sigma) P_2 (1|2|\ldots|\sigma) \ldots (1|2|\ldots|\sigma) P_{d}$, and Golan, Kopelowitz, and Porat~\cite{DBLP:journals/algorithmica/GolanKP19} showed that this problem can be solved by a randomized Monte Carlo algorithm in $\Oh(d \log m)$ space and $\Oh(d+\log m)$ time per character.

% Intuitions of the ideas and how it links to sketches.
We start by defining \emph{atomic strings} which are the strings obtained by just keeping the concatenation and splitting at union, Klenee star and parenthesis. They only contain characters of $\Sigma$ and there are $\Theta(d)$ of them. The set of atomic string for $R= \mathrm{GAT}(\mathrm{TA}\mid \mathrm{O})(\mathrm{CAT})^*$  is $\{$GAT,TA,O,CAT$\}$.
%
The basis of our approach is to store efficiently some specific occurrences of prefixes of the atomic strings. Those stored occurrences are then linked to test if there is a “partial” match of $R$ (Definition\ref*{def:partial_occ_regexp}). Because we only store few occurrences over periodic regions of the text, they can be very far apart with just a long periodic substring in between. To recompose a partial match, we must check if that long periodic substring corresponds to a run of the Thompson automaton, which we formulate as finding a path of specific weight in a multigraph. We then solve this graph problem efficiently by translating it into a circuit with addition and convolution gates that can be evaluated in a space-efficient manner using a general framework~\cite{LokshtanovN10,Bringmann17}. Additionally, we improve that framework by removing its dependency on the Extended Riemann Hypothesis (Theorem~\ref{thm:bombieri}). 
%Sketches
Here the main novel idea relating to sketches is how the specific occurrences we store are chosen. It is common in streaming algorithm to handle the aperiodic and periodic strings as two separate cases. Here we choose to apply this reasoning recursively on $\Oh(\log n)$ levels through the notion of ``anchor'' position (Definition~\ref{def:anchors}). For each atomic string (or one of its prefixes) and a given anchor, either there are just a few occurrences crossing the anchor we can afford to store them, or the region is periodic, and we can instead look at an earlier position. This is key to achieve the desired space complexity and storing just the occurrences strictly needed.


% Gapped
% Indexing

% PM

% Squares

% Part two

% LCS

% DTW

% XBWT